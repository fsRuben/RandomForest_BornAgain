{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report\n",
    "source_path = os.path.abspath('../src')\n",
    "output_path = os.path.abspath('../output')\n",
    "sys.path.append(source_path)\n",
    "import datasets as ds\n",
    "import random_forests as rf\n",
    "import persistence as tree_io\n",
    "import visualization as tree_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2af21d7c52d4296811b40d29be0c994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Objective:', index=3, options=(('Depth', 0), ('NbLeaves', 1), ('Depth > NbLeaves', 2), (…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cebc6f689bb4cc7a7376d399c9b0a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, continuous_update=False, description='#Trees:', max=500, min=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b56901aefa4ccf86f3e06c46285a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, continuous_update=False, description='Fold:', max=10, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9106550ebf44da6995a7554bad12224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Datasets', options=('Breast-Cancer-Wisconsin', 'COMPAS-ProPublica', 'FICO', 'HTRU2', 'Pima…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c93bccfdf34e9999a0afd5ebcabcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='CPLEX linking', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_n_obj = rf.create_objective_selection()\n",
    "selected_n_tree = rf.create_n_trees_selection()\n",
    "selected_kfold = ds.create_kfold_selection()\n",
    "selected_datasets = ds.create_dataset_selection() \n",
    "selected_cplex = ds.create_cplex_linking_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Parameters...\n",
    "current_obj = selected_n_obj.value\n",
    "current_dataset=ds.dataset_names[selected_datasets.index]\n",
    "current_fold = selected_kfold.value\n",
    "n_trees = selected_n_tree.value\n",
    "using_cplex = selected_cplex.value\n",
    "max_tree_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_obj_loop = [4]\n",
    "#current_dataset_loop = ['COMPAS-ProPublica', 'FICO', \n",
    " #                  'HTRU2', 'Pima-Diabetes', \n",
    "  #                 'Seeds', 'Breast-Cancer-Wisconsin']\n",
    "#current_dataset_loop = ['Breast-Cancer-Wisconsin']\n",
    "#current_fold_loop = [1,2,3,4,5,6,7,8,9,10]\n",
    "current_fold_loop = [1,2,3]\n",
    "#n_trees_loop = [5, 10, 50, 100, 250, 500]\n",
    "n_trees_loop = [5, 10, 50]\n",
    "using_cplex_loop = False\n",
    "max_tree_depth_loop = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dataset_loop = ['COMPAS-ProPublica', 'FICO', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the directory using os.path.join for cross-platform compatibility\n",
    "src_path = os.path.join('..', 'src', 'born_again_dp')\n",
    "# Construct the make command dynamically\n",
    "make_command = f\"make --directory={src_path} {('withCPLEX=1' if using_cplex else '')} > buildlog.txt\"\n",
    "\n",
    "os.system(make_command)\n",
    "# make_command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected parameters:\n",
      "\n",
      "  Fold: 1\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 5\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 1\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 10\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 1\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 50\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 2\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 5\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 2\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 10\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 2\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 50\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 3\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 5\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 3\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 10\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 3\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 50\n",
      "  Dataset: COMPAS-ProPublica\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 1\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 5\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 1\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 10\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 1\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 50\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 2\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 5\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 2\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 10\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 2\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 50\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 3\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 5\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 3\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 10\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n",
      "Selected parameters:\n",
      "\n",
      "  Fold: 3\n",
      "  Objective: Heuristic\n",
      "  No. of trees: 50\n",
      "  Dataset: FICO\n",
      "  Using CPLEX: False\n",
      "Dynamic Program was successfully built.\n"
     ]
    }
   ],
   "source": [
    "for current_dataset in current_dataset_loop:\n",
    "    for current_fold in current_fold_loop:\n",
    "        for n_trees in n_trees_loop:\n",
    "            for max_tree_depth in max_tree_depth_loop:\n",
    "                print('Selected parameters:\\n')\n",
    "                print('  Fold:', current_fold)\n",
    "                print('  Objective:', selected_n_obj.label)\n",
    "                print('  No. of trees:', n_trees)\n",
    "                print('  Dataset:', current_dataset)\n",
    "                print('  Using CPLEX:', using_cplex)\n",
    "\n",
    "                # Loading data \n",
    "                df_train, df_test, ds_infos = ds.load(current_dataset, current_fold)\n",
    "                X_train, y_train = df_train.iloc[:,:-1].values, df_train.iloc[:,-1].values\n",
    "                X_test, y_test = df_test.iloc[:,:-1].values, df_test.iloc[:,-1].values\n",
    "\n",
    "\n",
    "                # Directly create the random forest instead of loading from a file\n",
    "                random_forest, random_forest_file = rf.create_random_forest(\n",
    "                    X_train, y_train, current_dataset, current_fold, max_tree_depth, n_trees, return_file=True\n",
    "                )\n",
    "\n",
    "                # Extract individual decision trees from the random forest\n",
    "                rf_trees = [e.tree_ for e in random_forest.estimators_]\n",
    "\n",
    "\n",
    "                # Define the path to the directory using os.path.join for cross-platform compatibility\n",
    "                src_path = os.path.join('..', 'src', 'born_again_dp')\n",
    "\n",
    "                # Construct the make command dynamically\n",
    "                make_command = f\"make --directory={src_path} {('withCPLEX=1' if using_cplex else '')} > buildlog.txt\"\n",
    "\n",
    "                # Execute the make command\n",
    "                if 0 == os.system(make_command):\n",
    "                    print('Dynamic Program was successfully built.')\n",
    "                else:\n",
    "                    print('Error while compiling the program with the make command. Please verify that a suitable compiler is available.')\n",
    "                    # Retry the make command without redirecting output to a file for debugging purposes\n",
    "                    os.system(f\"make --directory={src_path}\")\n",
    "\n",
    "                #display(Image(tree_view.create_graph(rf_trees, features=ds_infos['features'], classes=ds_infos['classes'], colors=ds_infos['colors']).create_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output_new/Born_Again/COMPAS-ProPublica/COMPAS-ProPublica.BA1.O4.T5.tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19264\\1716163162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;31m# Load Born-Again Trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mborn_again\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborn_again_file\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".tree\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mborn_again_pruned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborn_again_file\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".tree\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ruben\\OneDrive\\Documents\\RandomForest_BornAgain\\src\\persistence.py\u001b[0m in \u001b[0;36mclassifier_from_file\u001b[1;34m(fn, X, y, pruning, compute_score, num_trees)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[0mnumOfClasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxTreeDepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[0mchildren_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_depths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m     \u001b[0mis_leaves\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmajorityClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportTreeCollection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumOfFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ruben\\OneDrive\\Documents\\RandomForest_BornAgain\\src\\persistence.py\u001b[0m in \u001b[0;36mimportTreeCollection\u001b[1;34m(datasetName, silent)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mnew_nodeValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mnew_majorityClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasetName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minputFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_new/Born_Again/COMPAS-ProPublica/COMPAS-ProPublica.BA1.O4.T5.tree'"
     ]
    }
   ],
   "source": [
    "# Create directories for saving figures\n",
    "figure_output_dir = \"output_new/Figures\"\n",
    "os.makedirs(figure_output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize results dictionary\n",
    "aggregated_results = []\n",
    "\n",
    "for current_dataset in current_dataset_loop:\n",
    "    for n_trees in n_trees_loop:\n",
    "        for max_tree_depth in max_tree_depth_loop:\n",
    "\n",
    "            # Temporary storage for fold-specific results\n",
    "            fold_metrics = {\n",
    "                \"RandomForest\": {\"Train Acc\": [], \"Train F1\": [], \"Test Acc\": [], \"Test F1\": [], \"Leaves\": []},\n",
    "                \"BornAgain\": {\"Train Acc\": [], \"Train F1\": [], \"Test Acc\": [], \"Test F1\": [], \"Leaves\": []},\n",
    "                \"BornAgain-Pruned\": {\"Train Acc\": [], \"Train F1\": [], \"Test Acc\": [], \"Test F1\": [], \"Leaves\": []},\n",
    "            }\n",
    "\n",
    "            for current_fold in current_fold_loop:\n",
    "\n",
    "                 # Loading data \n",
    "                df_train, df_test, ds_infos = ds.load(current_dataset, current_fold)\n",
    "                X_train, y_train = df_train.iloc[:,:-1].values, df_train.iloc[:,-1].values\n",
    "                X_test, y_test = df_test.iloc[:,:-1].values, df_test.iloc[:,-1].values\n",
    "\n",
    "                # Define paths\n",
    "                born_again_file = f\"output_new/Born_Again/{current_dataset}/{current_dataset}.BA{current_fold}.O{current_obj}.T{n_trees}\"\n",
    "                random_forest_file = f\"output_new/RF/{current_dataset}/{current_dataset}.RF{current_fold}.T{n_trees}.txt\"\n",
    "\n",
    "                # Load Random Forest\n",
    "                random_forest = tree_io.classifier_from_file(random_forest_file, X_train, y_train, pruning=False)\n",
    "\n",
    "                # Load Born-Again Trees\n",
    "                born_again = tree_io.classifier_from_file(born_again_file + \".tree\", X_train, y_train, pruning=False)\n",
    "                born_again_pruned = tree_io.classifier_from_file(born_again_file + \".tree\", X_train, y_train, pruning=True)\n",
    "\n",
    "                # Visualize the pruned Born-Again tree\n",
    "                pruned_graph = tree_view.create_graph(\n",
    "                    [born_again_pruned.tree_],  # Pass the tree object\n",
    "                    features=ds_infos['features'],  # Feature names\n",
    "                    classes=ds_infos['classes'],  # Class labels\n",
    "                    colors=ds_infos['colors']  # Colors for visualization\n",
    "                )\n",
    "\n",
    "                # Save pruned graph as PNG\n",
    "                pruned_output_path = os.path.join(\n",
    "                    figure_output_dir,\n",
    "                    f\"{current_dataset}_Fold{current_fold}_Trees{n_trees}_Depth{max_tree_depth}_Pruned.png\"\n",
    "                )\n",
    "                with open(pruned_output_path, \"wb\") as f:\n",
    "                    f.write(pruned_graph.create_png())\n",
    "                \n",
    "                if n_trees == 5:\n",
    "                    #Save unpruned graph (optional)\n",
    "                    unpruned_graph = tree_view.create_graph(\n",
    "                        [born_again.tree_],\n",
    "                        features=ds_infos['features'],\n",
    "                        classes=ds_infos['classes'],\n",
    "                        colors=ds_infos['colors']\n",
    "                    )\n",
    "                    unpruned_output_path = os.path.join(\n",
    "                        figure_output_dir,\n",
    "                        f\"{current_dataset}_Fold{current_fold}_Trees{n_trees}_Depth{max_tree_depth}_Unpruned.png\"\n",
    "                    )\n",
    "                    with open(unpruned_output_path, \"wb\") as f:\n",
    "                        f.write(unpruned_graph.create_png())\n",
    "\n",
    "                # Calculate leaves\n",
    "                total_rf_leaves = np.sum([tree.tree_.n_leaves for tree in random_forest.estimators_])\n",
    "                ba_leaves = born_again.tree_.n_leaves\n",
    "                ba_pruned_leaves = born_again_pruned.tree_.n_leaves\n",
    "\n",
    "                # Evaluate Random Forest\n",
    "                rf_test_pred = random_forest.predict(X_test)\n",
    "                rf_train_pred = random_forest.predict(X_train)\n",
    "                report_rf = classification_report(y_test, rf_test_pred, output_dict=True)\n",
    "                report_rf_train = classification_report(y_train, rf_train_pred, output_dict=True)\n",
    "\n",
    "                # Evaluate Born-Again Tree\n",
    "                ba_test_pred = born_again.predict(X_test)\n",
    "                ba_train_pred = born_again.predict(X_train)\n",
    "                report_ba = classification_report(y_test, ba_test_pred, output_dict=True)\n",
    "                report_ba_train = classification_report(y_train, ba_train_pred, output_dict=True)\n",
    "\n",
    "                # Evaluate Pruned Born-Again Tree\n",
    "                ba_pruned_test_pred = born_again_pruned.predict(X_test)\n",
    "                ba_pruned_train_pred = born_again_pruned.predict(X_train)\n",
    "                report_ba_pruned = classification_report(y_train, ba_pruned_train_pred, output_dict=True)\n",
    "                report_ba_pruned_train = classification_report(y_train, ba_pruned_train_pred, output_dict=True)\n",
    "\n",
    "                # Store fold-specific results\n",
    "                fold_metrics[\"RandomForest\"][\"Train Acc\"].append(report_rf_train['accuracy'])\n",
    "                fold_metrics[\"RandomForest\"][\"Train F1\"].append(report_rf_train['weighted avg']['f1-score'])\n",
    "                fold_metrics[\"RandomForest\"][\"Test Acc\"].append(report_rf['accuracy'])\n",
    "                fold_metrics[\"RandomForest\"][\"Test F1\"].append(report_rf['weighted avg']['f1-score'])\n",
    "                fold_metrics[\"RandomForest\"][\"Leaves\"].append(total_rf_leaves)\n",
    "\n",
    "                fold_metrics[\"BornAgain\"][\"Train Acc\"].append(report_ba_train['accuracy'])\n",
    "                fold_metrics[\"BornAgain\"][\"Train F1\"].append(report_ba_train['weighted avg']['f1-score'])\n",
    "                fold_metrics[\"BornAgain\"][\"Test Acc\"].append(report_ba['accuracy'])\n",
    "                fold_metrics[\"BornAgain\"][\"Test F1\"].append(report_ba['weighted avg']['f1-score'])\n",
    "                fold_metrics[\"BornAgain\"][\"Leaves\"].append(ba_leaves)\n",
    "\n",
    "                fold_metrics[\"BornAgain-Pruned\"][\"Train Acc\"].append(report_ba_pruned_train['accuracy'])\n",
    "                fold_metrics[\"BornAgain-Pruned\"][\"Train F1\"].append(report_ba_pruned_train['weighted avg']['f1-score'])\n",
    "                fold_metrics[\"BornAgain-Pruned\"][\"Test Acc\"].append(report_ba_pruned['accuracy'])\n",
    "                fold_metrics[\"BornAgain-Pruned\"][\"Test F1\"].append(report_ba_pruned['weighted avg']['f1-score'])\n",
    "                fold_metrics[\"BornAgain-Pruned\"][\"Leaves\"].append(ba_pruned_leaves)\n",
    "\n",
    "            # Compute mean across folds\n",
    "            for method in fold_metrics:\n",
    "                aggregated_results.append({\n",
    "                    \"Dataset\": current_dataset,\n",
    "                    \"Trees\": n_trees,\n",
    "                    \"Max Depth\": max_tree_depth,\n",
    "                    \"Method\": method,\n",
    "                    \"Train Acc\": np.mean(fold_metrics[method][\"Train Acc\"]),\n",
    "                    \"Train F1\": np.mean(fold_metrics[method][\"Train F1\"]),\n",
    "                    \"Test Acc\": np.mean(fold_metrics[method][\"Test Acc\"]),\n",
    "                    \"Test F1\": np.mean(fold_metrics[method][\"Test F1\"]),\n",
    "                    \"Leaves\": np.mean(fold_metrics[method][\"Leaves\"]),\n",
    "                })\n",
    "\n",
    "# Convert aggregated results to a DataFrame\n",
    "results_df = pd.DataFrame(aggregated_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
